{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee09eac-062c-49db-9547-086d75a0dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En primer lugar he usado el prompt que he usado es el siguiente:\n",
    "\"\"\"\n",
    "\n",
    "*Código entero en java*\n",
    "***\n",
    "\n",
    "Dado el código de mi proyecto que usa spark mediante JAVA. Quiero que hagas una versión Python con exactamente el mismo comportamiento.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c706cb6-0f74-4280-bb53-8ab00fdabf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultado esperado: Number of crimes of type THEFT: 1736434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25e4c3-8017-4da2-b39e-d20f646f2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHATGPT 4O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7c444-4402-4506-a22e-5a514ab74661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, IntegerType, StringType, BooleanType, DoubleType\n",
    ")\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Desactivar logs innecesarios\n",
    "import logging\n",
    "logger = logging.getLogger(\"py4j\")\n",
    "logger.setLevel(logging.WARN)\n",
    "\n",
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark CSV Read Example\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir el esquema manualmente\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Case Number\", StringType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Block\", StringType(), True),\n",
    "    StructField(\"IUCR\", StringType(), True),\n",
    "    StructField(\"Primary Type\", StringType(), True),\n",
    "    StructField(\"Description\", StringType(), True),\n",
    "    StructField(\"Location Description\", StringType(), True),\n",
    "    StructField(\"Arrest\", BooleanType(), True),\n",
    "    StructField(\"Domestic\", BooleanType(), True),\n",
    "    StructField(\"Beat\", IntegerType(), True),\n",
    "    StructField(\"District\", IntegerType(), True),\n",
    "    StructField(\"Ward\", IntegerType(), True),\n",
    "    StructField(\"Community Area\", IntegerType(), True),\n",
    "    StructField(\"FBI Code\", StringType(), True),\n",
    "    StructField(\"X Coordinate\", IntegerType(), True),\n",
    "    StructField(\"Y Coordinate\", IntegerType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Updated On\", StringType(), True),\n",
    "    StructField(\"Latitude\", DoubleType(), True),\n",
    "    StructField(\"Longitude\", DoubleType(), True),\n",
    "    StructField(\"Location\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Cargar el CSV con el esquema definido\n",
    "dataframe = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"data/Crimes_-_2001_to_Present.csv\") \\\n",
    "    .cache()\n",
    "\n",
    "# Mostrar el esquema y los primeros registros\n",
    "dataframe.printSchema()\n",
    "dataframe.show()\n",
    "\n",
    "print(\"Time before grouping:\", time.time() - start_time)\n",
    "\n",
    "# Agrupar por \"Primary Type\" y ordenar por número de casos\n",
    "categories = dataframe.groupBy(\"Primary Type\").count().orderBy(col(\"count\").desc())\n",
    "\n",
    "categories.printSchema()\n",
    "categories.show()\n",
    "\n",
    "print(\"Time before filtering:\", time.time() - start_time)\n",
    "\n",
    "# Contar los crímenes de tipo \"THEFT\"\n",
    "number_of_crimes_of_primary_type = dataframe.filter(col(\"Primary Type\") == \"THEFT\").count()\n",
    "\n",
    "print(\"Total time:\", time.time() - start_time)\n",
    "print(f\"Number of crimes of type THEFT: {number_of_crimes_of_primary_type}\")\n",
    "\n",
    "# Finalizar sesión de Spark\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695dafb-b0af-459f-a040-315e72b2e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El resultado obtenido Coincide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f12ccb-c99a-47be-af56-e1839a89c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEPSEEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f42a065-a8f3-4357-ae1d-5d6432da8956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import time\n",
    "\n",
    "# Inicializar la sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Python Spark SQL. Example of reading a CSV file\") \\\n",
    "    .master(\"local[8]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Desactivar los logs de INFO y WARN\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Definir el esquema explícito para el DataFrame\n",
    "schema = \"ID INT, `Case Number` STRING, Date STRING, Block STRING, IUCR STRING, \" \\\n",
    "         \"`Primary Type` STRING, Description STRING, `Location Description` STRING, \" \\\n",
    "         \"Arrest BOOLEAN, Domestic BOOLEAN, Beat INT, District INT, Ward INT, \" \\\n",
    "         \"`Community Area` INT, `FBI Code` STRING, `X Coordinate` INT, `Y Coordinate` INT, \" \\\n",
    "         \"Year INT, `Updated On` STRING, Latitude DOUBLE, Longitude DOUBLE, Location STRING\"\n",
    "\n",
    "# Leer el archivo CSV con el esquema definido\n",
    "df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"false\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"data/Crimes_-_2001_to_Present.csv\") \\\n",
    "    .cache()\n",
    "\n",
    "# Mostrar el esquema y los primeros registros del DataFrame\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "print(f\"Time before grouping: {time.time() - start_time}\")\n",
    "\n",
    "# Agrupar por 'Primary Type' y contar, luego ordenar por el conteo en orden descendente\n",
    "categories = df.groupBy(\"Primary Type\").count().sort(col(\"count\").desc())\n",
    "\n",
    "# Mostrar el esquema y los resultados de la agrupación\n",
    "categories.printSchema()\n",
    "categories.show()\n",
    "\n",
    "print(f\"Time before filtering: {time.time() - start_time}\")\n",
    "\n",
    "# Filtrar los registros donde 'Primary Type' es 'THEFT' y contar\n",
    "number_of_crimes_of_primary_type = df.filter(col(\"Primary Type\") == \"THEFT\").count()\n",
    "\n",
    "print(f\"Total time: {time.time() - start_time}\")\n",
    "print(f\"Number of crimes of type THEFT: {number_of_crimes_of_primary_type}\")\n",
    "\n",
    "# Detener la sesión de Spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508b867-b212-44d2-8b7e-a714a0c9af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El resultado también coincide pero define el esquema de otra forma."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profiling",
   "language": "python",
   "name": "profiling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
