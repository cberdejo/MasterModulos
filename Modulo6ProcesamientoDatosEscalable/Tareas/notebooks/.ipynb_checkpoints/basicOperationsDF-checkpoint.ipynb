{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee5caa1f-98a5-4e74-8bea-c76754ca706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.functions import to_timestamp, col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c5916c7-b780-4fa5-af6c-22595a6c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea una sesión, o en caso de que ya exista se recupera\n",
    "spark_session = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Simple program to show the basics of Spark dataframes\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f85e3c-57fd-497a-a372-581eeb7da70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Leemos los datos y le decimos que infiera el schema, es decir los tipos de datos para cada variable\n",
    "data_frame = spark_session \\\n",
    "    .read \\\n",
    "    .options(header='true', inferschema='true') \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"timestampFormat\", \"yyyy-MM-dd\") \\\n",
    "    .csv(\"C:/Users/cberd/Desktop/Master/Modulo6ProcesamientoDatosEscalable/Tareas/ProyectoPythonSpark/data/personalData.csv\") \\\n",
    "    .persist()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f58d82-6949-425c-8c60-ad91c790c247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame schema\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      " |-- HasACar: boolean (nullable = true)\n",
      " |-- BirthDate: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Podemos mostrar el schema inferido de la lectura\n",
    "print(\"Data frame schema\") \n",
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72bdc257-1592-4b48-847a-5206eab691fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame\n",
      "+------+---+------+-------+----------+\n",
      "|  Name|Age|Weight|HasACar| BirthDate|\n",
      "+------+---+------+-------+----------+\n",
      "|  Luis| 23|  84.5|   true|2019-02-28|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03|\n",
      "|Manolo| 68|  75.3|   true|2000-01-04|\n",
      "+------+---+------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se muestra el dataframe, por defecto show muestra solo los 20 primeros\n",
    "print (\"Data frame\")\n",
    "data_frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9eee28d-8c10-4709-b9be-eb88ae17b57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types: [('Name', 'string'), ('Age', 'int'), ('Weight', 'double'), ('HasACar', 'boolean'), ('BirthDate', 'date')]\n"
     ]
    }
   ],
   "source": [
    "#Podemos ver los tipos de cada atirbuto\n",
    "print(\"data types: \" + str(data_frame.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aecd49f-de44-4623-b2ce-ba43e52b5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the dataframe\n",
      "+-------+----+------------------+-----------------+\n",
      "|summary|Name|               Age|           Weight|\n",
      "+-------+----+------------------+-----------------+\n",
      "|  count|   4|                 4|                4|\n",
      "|   mean|null|             49.75|80.02499999999999|\n",
      "| stddev|null|21.391197566600457|8.951489633947338|\n",
      "|    min|Lola|                23|             70.2|\n",
      "|    max|Paco|                68|             90.1|\n",
      "+-------+----+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Se describe el dataframe, es decir ver valores estadísticos como la media,máximo, mínimo,...\n",
    "print (\"Describe the dataframe\")\n",
    "data_frame \\\n",
    "    .describe() \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea213c85-3f47-4cb6-a2bd-271256561c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the dataframe\n",
      "== Physical Plan ==\n",
      "InMemoryTableScan [Name#17, Age#18, Weight#19, HasACar#20, BirthDate#21]\n",
      "   +- InMemoryRelation [Name#17, Age#18, Weight#19, HasACar#20, BirthDate#21], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- FileScan csv [Name#17,Age#18,Weight#19,HasACar#20,BirthDate#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/cberd/Desktop/Master/Modulo6ProcesamientoDatosEscalable..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Name:string,Age:int,Weight:double,HasACar:boolean,BirthDate:date>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Explica cómo Spark procesará los datos en la memoria y en disco\n",
    "print (\"Explain the dataframe\")\n",
    "data_frame \\\n",
    "    .explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f0151f-17bd-4159-9f0a-111373a63599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform the date to the format used in Spark 3.0\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      " |-- HasACar: boolean (nullable = true)\n",
      " |-- BirthDate: timestamp (nullable = true)\n",
      "\n",
      "+------+---+------+-------+-------------------+\n",
      "|  Name|Age|Weight|HasACar|          BirthDate|\n",
      "+------+---+------+-------+-------------------+\n",
      "|  Luis| 23|  84.5|   true|2019-02-28 00:00:00|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01 00:00:00|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03 00:00:00|\n",
      "|Manolo| 68|  75.3|   true|2000-01-04 00:00:00|\n",
      "+------+---+------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se transforma el formato de la fecha al formato usado en Spark 3.0\n",
    "print (\"Transform the date to the format used in Spark 3.0\")\n",
    "data_frame = data_frame.withColumn(\"BirthDate\", to_timestamp(\"BirthDate\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Se muestra el resultado\n",
    "data_frame.printSchema()\n",
    "data_frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3421d508-c39b-44d2-a010-590b89ae1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se pueden realizar operaciones de data frames comunes (select,group by, count, order by, where, join,...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aff2660-c006-4ad3-a223-80994b7f178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the name and age columns\n",
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|  Luis| 23|\n",
      "|  Lola| 42|\n",
      "|  Paco| 66|\n",
      "|Manolo| 68|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Por ejemplo seleccionamos la columna de nombre y edad\n",
    "print (\"Select the name and age columns\")\n",
    "data_frame.select(\"Name\", \"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b77485c-0cf2-43c1-9e8a-3aa39e32da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select columns name and age, but adding 1 to age\n",
      "+------+---------+\n",
      "|  Name|(Age + 1)|\n",
      "+------+---------+\n",
      "|  Luis|       24|\n",
      "|  Lola|       43|\n",
      "|  Paco|       67|\n",
      "|Manolo|       69|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Podríamos también hacer operaciones en las columnas que seleccionamos y al mostrarlas por consola nos indicaría la operación realizada\n",
    "print (\"Select columns name and age, but adding 1 to age\")\n",
    "data_frame.select(\"Name\", data_frame[\"Age\"] + 1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5457fd91-4fac-4d29-9c01-eb16f2eb7c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicates whether the rows have a name length > 4\n",
      "+------------------+\n",
      "|(length(Name) > 4)|\n",
      "+------------------+\n",
      "|             false|\n",
      "|             false|\n",
      "|             false|\n",
      "|              true|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo que indica para cada fila si el nombre es mayor que 4\n",
    "print (\"Indicates whether the rows have a name length > 4\")\n",
    "data_frame.select(functions.length(data_frame[\"Name\"]) > 4).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "633eb6c7-7db4-48b4-929f-9f4fb0cd569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicates whether the names start with L\n",
      "+------+-------------------+\n",
      "|  name|startswith(name, L)|\n",
      "+------+-------------------+\n",
      "|  Luis|               true|\n",
      "|  Lola|               true|\n",
      "|  Paco|              false|\n",
      "|Manolo|              false|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#De forma similar podríamos ver si el nombre empieza por L\n",
    "print (\"Indicates whether the names start with L\")\n",
    "data_frame.select(data_frame[\"name\"], data_frame[\"name\"].startswith(\"L\")) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f76a5f-2964-4157-81f6-93ef089f9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "También podemos editar el nombre de columnas, eliminarlas, añadir columnas y \n",
    "por supuesto añadir condiciones para ejecutar estas operaciones. \n",
    "Por ejemplo:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "772b10c0-a1c4-4c22-871e-c8104056dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add a new column Senior containing true if the person age is > 45\n",
      "+------+---+------+-------+-------------------+------+\n",
      "|  Name|Age|Weight|HasACar|          BirthDate|Senior|\n",
      "+------+---+------+-------+-------------------+------+\n",
      "|  Luis| 23|  84.5|   true|2019-02-28 00:00:00| false|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01 00:00:00| false|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03 00:00:00|  true|\n",
      "|Manolo| 68|  75.3|   true|2000-01-04 00:00:00|  true|\n",
      "+------+---+------+-------+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Añadir una nueva columna donde el resultado sea true si la edad es mayor que 45\n",
    "print (\"Add a new column Senior containing true if the person age is > 45\")\n",
    "data_frame.withColumn(\"Senior\", data_frame[\"Age\"] > 45) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7366d3b-9edf-4703-b37d-06529832eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename column HasACar as Owner\n",
      "+------+---+------+-----+-------------------+\n",
      "|  Name|Age|Weight|Owner|          BirthDate|\n",
      "+------+---+------+-----+-------------------+\n",
      "|  Luis| 23|  84.5| true|2019-02-28 00:00:00|\n",
      "|  Lola| 42|  70.2|false|2000-10-01 00:00:00|\n",
      "|  Paco| 66|  90.1|false|1905-12-03 00:00:00|\n",
      "|Manolo| 68|  75.3| true|2000-01-04 00:00:00|\n",
      "+------+---+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombrar la columna HasACar\n",
    "print (\"Rename column HasACar as Owner\")\n",
    "data_frame.withColumnRenamed(\"HasACar\", \"Owner\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6fec4bb-83cf-4c72-b35d-79b26eae1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove column DateBirth\n",
      "+------+---+------+-------+\n",
      "|  Name|Age|Weight|HasACar|\n",
      "+------+---+------+-------+\n",
      "|  Luis| 23|  84.5|   true|\n",
      "|  Lola| 42|  70.2|  false|\n",
      "|  Paco| 66|  90.1|  false|\n",
      "|Manolo| 68|  75.3|   true|\n",
      "+------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Eliminar una columna\n",
    "print (\"Remove column DateBirth\")\n",
    "data_frame.drop(\"BirthDate\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "566978ad-56a8-4d25-9a4d-599a2da0d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort by age (descending)\n",
      "+------+---+------+-------+-------------------+\n",
      "|  Name|Age|Weight|HasACar|          BirthDate|\n",
      "+------+---+------+-------+-------------------+\n",
      "|Manolo| 68|  75.3|   true|2000-01-04 00:00:00|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03 00:00:00|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01 00:00:00|\n",
      "|  Luis| 23|  84.5|   true|2019-02-28 00:00:00|\n",
      "+------+---+------+-------+-------------------+\n",
      "\n",
      "+------+---+------+-------+-------------------+\n",
      "|  Name|Age|Weight|HasACar|          BirthDate|\n",
      "+------+---+------+-------+-------------------+\n",
      "|Manolo| 68|  75.3|   true|2000-01-04 00:00:00|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03 00:00:00|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01 00:00:00|\n",
      "|  Luis| 23|  84.5|   true|2019-02-28 00:00:00|\n",
      "+------+---+------+-------+-------------------+\n",
      "\n",
      "+------+---+------+-------+-------------------+\n",
      "|  Name|Age|Weight|HasACar|          BirthDate|\n",
      "+------+---+------+-------+-------------------+\n",
      "|Manolo| 68|  75.3|   true|2000-01-04 00:00:00|\n",
      "|  Paco| 66|  90.1|  false|1905-12-03 00:00:00|\n",
      "|  Lola| 42|  70.2|  false|2000-10-01 00:00:00|\n",
      "|  Luis| 23|  84.5|   true|2019-02-28 00:00:00|\n",
      "+------+---+------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Siguiendo con los ejemplos de operaciones, podemos hacer un sort. Como vemos es posible hacerlo usando un sort o un orderBy\n",
    "print (\"Sort by age (descending)\")\n",
    "#Ambos sorts son equivalentes aunque con simtaxis distintas\n",
    "data_frame.sort(data_frame.Age.desc()).show() #por fecha descendente\n",
    "data_frame.sort(\"Age\", ascending=False).show() #por fecha descendente\n",
    "\n",
    "data_frame.orderBy([\"Age\", \"Weight\"], ascending=[0, 1]).show() #se ordena primero por fecha descendentemente y en caso de empate por peso ascendentemente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5d5b8-06ce-41a2-830a-c8ad9a838d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podriamos convertir a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ec92660-9e6e-4a9b-9d90-aa59fda54647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a RDD\n",
    "rdd_from_dataframe = data_frame \\\n",
    "    .rdd \\\n",
    "    .persist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b9b6a8e-96f9-4e0d-8883-4d72b10e619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPodríamos realizar varias operaciones de forma equivalente usando rdd y data frames. De forma general leer usando dataframes el archivo\\npuede ser algo mas lento, ya que está infiriendo los tipos y el schema pero luego las operaciones, filtros, reordenaciones suelen ser más rápida.\\nComo se supone que el adecuado uso de spark conlleva pocas lecturas, podría ser interesante usar data frames. Además aporta mas legibilidad.\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Podríamos realizar varias operaciones de forma equivalente usando rdd y data frames. De forma general leer usando dataframes el archivo\n",
    "puede ser algo mas lento, ya que está infiriendo los tipos y el schema pero luego las operaciones, filtros, reordenaciones suelen ser más rápida.\n",
    "Como se supone que el adecuado uso de spark conlleva pocas lecturas, podría ser interesante usar data frames. Además aporta mas legibilidad.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173013c0-5124-4222-a5d4-324396efe46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suma de todos los pesos RDD VS DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0983fd2-640b-43eb-a671-28614d298ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma de pesos (RDD)\n",
    "sum_of_weights = rdd_from_dataframe \\\n",
    "    .map(lambda row: row[2]) \\\n",
    "    .reduce(lambda x, y: x + y)  # sum()\n",
    "print(\"Sum of weights (RDDs): \" + str(sum_of_weights))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d560bf73-60d4-4a49-88a0-d20e20a1cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(sum(Weight)=320.09999999999997)]\n",
      "Sum of weights (dataframe): 320.09999999999997\n",
      "+------------------+\n",
      "|       sum(Weight)|\n",
      "+------------------+\n",
      "|320.09999999999997|\n",
      "+------------------+\n",
      "\n",
      "+------------------+--------+\n",
      "|       sum(Weight)|min(Age)|\n",
      "+------------------+--------+\n",
      "|320.09999999999997|      23|\n",
      "+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Usando un dataframe podemos calcularlo de muchas maneras. Por ejemplo:\n",
    "weights = data_frame \\\n",
    "    .select(\"Weight\") \\\n",
    "    .groupBy() \\\n",
    "    .sum() \\\n",
    "    .collect()\n",
    "\n",
    "print(weights)\n",
    "\n",
    "print(\"Sum of weights (dataframe): \" + str(weights[0][0]))\n",
    "\n",
    "data_frame.select(functions.sum(data_frame[\"Weight\"])).show()\n",
    "data_frame.agg({\"Weight\": \"sum\", \"Age\": \"min\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa1da2-85c5-4667-ad33-8bfc92671114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edad media RDD VS DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bc0447-3c6e-48ef-8bbb-de096d30bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Media con RDD\n",
    "total_age = rdd_from_dataframe \\\n",
    "    .map(lambda row: row[1]) \\\n",
    "    .reduce(lambda x, y: x + y)\n",
    "\n",
    "mean_age = total_age / rdd_from_dataframe.count()\n",
    "print(\"Mean age (RDDs): \" + str(mean_age))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "20726f29-b7af-4619-bbb8-857230b9a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          Average|\n",
      "+-----------------+\n",
      "|80.02499999999999|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Weight)|\n",
      "+-----------------+\n",
      "|80.02499999999999|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Media con Dataframe, dos ejemplos:\n",
    "data_frame.select(functions.avg(data_frame[\"Weight\"])) \\\n",
    "    .withColumnRenamed(\"avg(Weight)\", \"Average\") \\\n",
    "    .show()\n",
    "\n",
    "data_frame.agg({\"Weight\": \"avg\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc5592a5-4be1-457f-b02d-2864594bf81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|HasACar|count|\n",
      "+-------+-----+\n",
      "|   true|    2|\n",
      "|  false|    2|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Otro ejemplo contar las personas según si tienen coche o no\n",
    "data_frame.groupBy(\"HasACar\")\\\n",
    "    .count()\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d863d25-dc90-4fd6-aa42-f87de459fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres únicos en el dataset (aparecen solo una vez):\n",
      "+------+-----+\n",
      "|  Name|count|\n",
      "+------+-----+\n",
      "|  Lola|    1|\n",
      "|  Paco|    1|\n",
      "|  Luis|    1|\n",
      "|Manolo|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Como último ejemplo podríamos ver que nombres son únicos:\n",
    "\n",
    "\n",
    "# Contar cuántas veces aparece cada nombre\n",
    "name_counts = data_frame.groupBy(\"Name\").count()\n",
    "\n",
    "# Filtrar solo los nombres que aparecen exactamente una vez\n",
    "unique_names = name_counts.filter(col(\"count\") == 1)\n",
    "\n",
    "# Mostrar los nombres únicos\n",
    "print(\"Nombres únicos en el dataset (aparecen solo una vez):\")\n",
    "unique_names.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd2093-4df9-4522-93d2-165495d47559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos escribir el resultado en un archivo JSON O CSV\n",
    "# Write to a json file\n",
    "data_frame\\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"output.json\", format=\"json\")\n",
    "\n",
    "# Write to a CSV file\n",
    "data_frame\\\n",
    "    .write\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"output.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profiling",
   "language": "python",
   "name": "profiling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
