{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT_qZ-6tqR60"
      },
      "source": [
        "# Performance comparison between Spark and other systems\n",
        "\n",
        "*Systems used for comparisons:*\n",
        "\n",
        "1.   PySpark dataframes\n",
        "1.   PySpark RDD\n",
        "1.   Pandas\n",
        "1.   Polars\n",
        "\n",
        "*Data link:*https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-Present/ijzp-q8t2/data\n",
        "\n",
        "*Perfomance measured for these operations:*\n",
        "1. read file\n",
        "1. filter by arrested\n",
        "1. group by district\n",
        "1. count all criminal arrested by district\n",
        "1. order by\n",
        "\n",
        "*Authors*:\n",
        "- Pablo Nieto Rodríguez\n",
        "- Pablo Fontádez\n",
        "- Christian Berdejo Sánchez\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak4iZbzWxOf8",
        "outputId": "03c9f5ac-5388-4bf5-e289-1cff924a61c3"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_file=\"./data/Crimes_-_2001_to_Present.csv\" #sustituir por fichero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gj8eVXKRbY0O"
      },
      "outputs": [],
      "source": [
        "import time # For measuring time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4dVuxj5tNCb"
      },
      "source": [
        "## CSV Performance comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb4qEhcNrUTt"
      },
      "source": [
        "### 1. PySpark dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HmBZwbY3X7xj"
      },
      "outputs": [],
      "source": [
        "#Install dependencies\n",
        "from pyspark.sql import SparkSession, functions\n",
        "from pyspark.sql.functions import to_timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EEUvYRzRYSeA"
      },
      "outputs": [],
      "source": [
        "#Create Spark Session\n",
        "spark_session = SparkSession \\\n",
        "        .builder \\\n",
        "        .getOrCreate()\n",
        "\n",
        "#Log Error\n",
        "spark_session.sparkContext.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n94yQ2ira09H"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mnb56nqapCe",
        "outputId": "49422e1f-d984-44e9-d9ed-69a2a469b67b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading time:  19.636226892471313\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "data_frame = spark_session \\\n",
        "      .read \\\n",
        "      .options(header='true', inferschema='true') \\\n",
        "      .option(\"delimiter\", \",\") \\\n",
        "      .option(\"timestampFormat\", \"yyyy-MM-dd\") \\\n",
        "      .csv(path_file) \\\n",
        "      .persist()\n",
        "\n",
        "dataframe_reading_time = time.time() - initial_time\n",
        "print(\"Reading time: \", str(dataframe_reading_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHEghuD1byZz"
      },
      "source": [
        " Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqCcmaNPb6fk",
        "outputId": "d95629ba-498e-4172-dd4d-e61ef6a96c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter time:  0.07268404960632324\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "filtered_df  = data_frame.filter(\"Arrest = true\")\n",
        "dataframe_filter_time = time.time() - initial_time\n",
        "print(\"Filter time: \", str(dataframe_filter_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws_4cbE_cc_J"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60ZneC58cez2",
        "outputId": "6bdbe31c-a5ef-484f-cfaa-1122742d780b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time:  0.03395581245422363\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "grouped_df = filtered_df.groupby(\"District\")\n",
        "dataframe_time_group_by = time.time() - start_time\n",
        "\n",
        "print(\"Group by time: \", str(dataframe_time_group_by))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ezTIWWSfX5s"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbylDxHMfUdw",
        "outputId": "4a4543ed-ab3e-41f3-d473-2d3f841e342f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count time:  0.04213404655456543\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "counted_df = grouped_df.count()\n",
        "\n",
        "dataframe_count_time = time.time() - start_time\n",
        "print(\"Count time: \", str(dataframe_count_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aKDGW_PfsRN"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QjUM_FmgzSI",
        "outputId": "3c83fabe-ce8f-4c22-8482-c8f87ccc4f19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sort time:  0.03127288818359375\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "sorted_df = counted_df.orderBy(\"count\", ascending=False)\n",
        "dataframe_time_sort = time.time() - start_time\n",
        "print(\"Sort time: \", str(dataframe_time_sort))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIzDlcdQrazX"
      },
      "source": [
        "###  2. PySpark RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9Mn5ptV7kdaG"
      },
      "outputs": [],
      "source": [
        "#Install dependencies\n",
        "from pyspark import SparkConf, SparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "WllkfCctkdaH"
      },
      "outputs": [],
      "source": [
        "# Crear SparkSession\n",
        "spark_session = SparkSession.builder \\\n",
        "    .appName(\"AddNumbers\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Obtener SparkContext desde SparkSession\n",
        "spark_context = spark_session.sparkContext\n",
        "\n",
        "spark_context.setLogLevel(\"ERROR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNaES9qZkdaH"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2y0lZIdkdaI",
        "outputId": "40336c4d-9c2e-4710-b543-5976d9c4554c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading time:  0.028599977493286133\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "\n",
        "rdd = spark_context.textFile(path_file)\n",
        "\n",
        "\n",
        "rdd_reading_time = time.time() - initial_time\n",
        "print(\"Reading time: \", str(rdd_reading_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "hB-dMa_w0HKc"
      },
      "outputs": [],
      "source": [
        "header = rdd.first()\n",
        "columns = header.split(\",\")\n",
        "\n",
        "try:\n",
        "    arrest_idx = columns.index(\"Arrest\")      # Ajusta al nombre exacto de tu columna\n",
        "    district_idx = columns.index(\"District\") # Ajusta al nombre exacto de tu columna\n",
        "except ValueError:\n",
        "    print(\"Verifica que tus columnas 'Arrest' y 'District' existan en el header.\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "IV51EQpw2HH2"
      },
      "outputs": [],
      "source": [
        "rdd_no_header = rdd.filter(lambda line: line != header)\n",
        "rdd_parsed = rdd_no_header.map(lambda line: line.split(\",\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kWAKWFbkdaI"
      },
      "source": [
        "Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toV-PXBqkdaI",
        "outputId": "1777d279-7062-4f90-cc6b-1481bb114c6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter time:  0.0\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "rdd_filtered = rdd_parsed.filter(\n",
        "    lambda row: len(row) > max(arrest_idx, district_idx) and row[arrest_idx].lower() == \"true\"\n",
        ")\n",
        "rdd_filter_time = time.time() - initial_time\n",
        "print(\"Filter time: \", str(rdd_filter_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5WoUj7kdaI"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8nVGmv4kdaJ",
        "outputId": "a45e53d9-c2be-4e71-aaab-4854c327c42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time:  0.0\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_mapped = rdd_filtered.map(lambda row: (row[district_idx], 1))\n",
        "\n",
        "rdd_time_group_by = time.time() - start_time\n",
        "\n",
        "print(\"Group by time: \", str(rdd_time_group_by))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtgLslGqkdaJ"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q49MvAW8kdaJ",
        "outputId": "e8d52d31-184e-4e05-ffad-cd57ef2dd08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count time:  0.02471184730529785\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_counted = rdd_mapped.reduceByKey(lambda a, b: a + b)\n",
        "rdd_count_time = time.time() - start_time\n",
        "print(\"Count time: \", str(rdd_count_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OHDgyN7kdaJ"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLGsXfawkdaK",
        "outputId": "317bb914-0e28-4af2-e234-61b73e4e2447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('011', 211323), ('015', 130453), ('007', 125371), ('025', 118957), ('006', 116946)]\n",
            "Sort time:  148.438649892807\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_sorted = rdd_counted.sortBy(lambda x: x[1], ascending=False)\n",
        "rdd_time_sort = time.time() - start_time\n",
        "print(\"Sort time: \", str(rdd_time_sort))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SObwnforvLF"
      },
      "source": [
        "### 3. Pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH6yeIgzC4tp",
        "outputId": "79e38e7f-ee59-45a7-ed0e-9c28b266eb2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de lectura: 86.904929 segundos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "df = pd.read_csv(path_file, delimiter=\",\", low_memory=False)\n",
        "pd_read_time = time.time() - start_time\n",
        "print(f\"Tiempo de lectura: {pd_read_time:.6f} segundos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ-RW5p-DLXX",
        "outputId": "c0f77779-1db1-4a5b-e272-7abc2572ba76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de filtrado: 0.968046 segundos\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "filtered_df = df[df[\"Arrest\"] == True]\n",
        "pd_filter_time = time.time() - start_time\n",
        "print(f\"Tiempo de filtrado: {pd_filter_time:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CU-PnmbDOAz",
        "outputId": "a0d20a8c-ffae-45ba-f58c-4f1bdb9da7fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de agrupación: 0.077922 segundos\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "grouped_df = filtered_df.groupby(\"District\").size()\n",
        "pd_group_time = time.time() - start_time\n",
        "print(f\"Tiempo de agrupación: {pd_group_time:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_0OWge4DTNJ",
        "outputId": "b8feef97-7b48-44e5-bf3f-5a8b2a855c52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de conteo: 0.058875 segundos\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "counted_df = grouped_df.reset_index(name=\"count\")\n",
        "pd_count_time = time.time() - start_time\n",
        "print(f\"Tiempo de conteo: {pd_count_time:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MizpjSRNDV_C",
        "outputId": "b0ec7691-31f7-429f-9fc9-b101d9fe43ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo de ordenamiento: 0.006889 segundos\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "sorted_df = counted_df.sort_values(by=\"count\", ascending=False)\n",
        "pd_sort_time = time.time() - start_time\n",
        "print(f\"Tiempo de ordenamiento: {pd_sort_time:.6f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i75KKH_Mr2eM"
      },
      "source": [
        "### 4. Polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4-thPXx0sdLu"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18UrHtKhsfkD"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AFCvPROsiLu",
        "outputId": "7013b9b5-0d21-4977-fa89-d1bc5e066335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading time:  17.826291799545288\n"
          ]
        }
      ],
      "source": [
        "start_computing_time = time.time()\n",
        "df=pl.read_csv(path_file)\n",
        "pl_reading_time= time.time()-start_computing_time\n",
        "print(\"Reading time: \",pl_reading_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhfEOpNUskV0"
      },
      "source": [
        "Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzQM_EiospSX",
        "outputId": "ccbf5043-56be-4bea-d44b-27b6167cafaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter time:  2.0957674980163574\n"
          ]
        }
      ],
      "source": [
        "start_computing_time = time.time()\n",
        "filter_df= df.filter(pl.col(\"Arrest\") == True)\n",
        "pl_filter_time= time.time()-start_computing_time\n",
        "print(\"Filter time: \",pl_filter_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UUN6Tp6sshW"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTW4XIR3srkg",
        "outputId": "e1adbde3-e87b-462b-99b2-f9c52a504a15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time:  0.003191709518432617\n"
          ]
        }
      ],
      "source": [
        "start_computing_time = time.time()\n",
        "grouped_df=filter_df.group_by(\"District\")\n",
        "pl_group_time= time.time()-start_computing_time\n",
        "print(\"Group by time: \",pl_group_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4rlBD1_ci4B",
        "outputId": "5a4838f5-b85b-4921-d44c-65e30819db0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time:  0.07523155212402344\n"
          ]
        }
      ],
      "source": [
        "start_computing_time = time.time()\n",
        "count_df=grouped_df.agg(pl.len().alias(\"count\"))\n",
        "pl_count_time= time.time()-start_computing_time\n",
        "print(\"Group by time: \",pl_count_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnOupqgzs492"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG6zv8_tsvzm",
        "outputId": "d402d4c0-ca82-449f-c5d3-997a3443943b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sort by time:  0.006716489791870117\n"
          ]
        }
      ],
      "source": [
        "start_computing_time = time.time()\n",
        "sort_df = count_df.sort(\"count\", descending=True)\n",
        "pl_sort_time= time.time()-start_computing_time\n",
        "print(\"Sort by time: \",pl_sort_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsFyOysNtYTM"
      },
      "source": [
        "Total time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0P3nSg3sxmY",
        "outputId": "7c08ccb0-5023-4186-a7bf-03f1412c3a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total time:  20.00719904899597\n"
          ]
        }
      ],
      "source": [
        "pl_total_time=pl_reading_time+pl_filter_time+pl_group_time+pl_sort_time+pl_count_time\n",
        "print(\"Total time: \",pl_total_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSxT7kLrtXQy"
      },
      "source": [
        "## parquet Perfomance comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TORFaioupby"
      },
      "source": [
        "### Transform from CSV to parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "fnGG4DLDFpoq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "f-n9Ca4hFuCW"
      },
      "outputs": [],
      "source": [
        "data_csv = pd.read_csv(path_file)\n",
        "data_csv.to_parquet('data_parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "vcKQdMvIIM3k"
      },
      "outputs": [],
      "source": [
        "path_parquet_file=\"./data_parquet\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpZjSuv4uxsg"
      },
      "source": [
        "### 1. PySpark dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pB-Dw3Klwfj8"
      },
      "outputs": [],
      "source": [
        "#Install dependencies\n",
        "from pyspark.sql import SparkSession, functions\n",
        "from pyspark.sql.functions import to_timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Yyth5UPzwfj9"
      },
      "outputs": [],
      "source": [
        "#Create Spark Session\n",
        "spark_session = SparkSession \\\n",
        "        .builder \\\n",
        "        .getOrCreate()\n",
        "\n",
        "#Log Error\n",
        "spark_session.sparkContext.setLogLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKKtcTmhwfj9"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpB66rQRwfj9",
        "outputId": "5be07578-bcde-4eb4-c139-fa80c54d5d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading time:  4.546781778335571\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "data_frame = spark_session \\\n",
        "      .read \\\n",
        "      .options(header='true', inferschema='true') \\\n",
        "      .option(\"delimiter\", \",\") \\\n",
        "      .option(\"timestampFormat\", \"yyyy-MM-dd\") \\\n",
        "      .parquet(path_parquet_file) \\\n",
        "      .persist()\n",
        "\n",
        "dataframe_parquet_reading_time = time.time() - initial_time\n",
        "print(\"Reading time: \", str(dataframe_parquet_reading_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhsXWVhswfj-"
      },
      "source": [
        " Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvATIk9Iwfj-",
        "outputId": "436cb73a-0cdb-42d0-b42f-59e0e68eb5c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter time:  0.12954926490783691\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "filtered_df  = data_frame.filter(\"Arrest = true\")\n",
        "dataframe_parquet_filter_time = time.time() - initial_time\n",
        "print(\"Filter time: \", str(dataframe_parquet_filter_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjB7uxAOwfj-"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wL3l8tywfj-",
        "outputId": "34dc704e-fa73-45af-acc7-c5f75f420ec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time:  0.06593108177185059\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "grouped_df = filtered_df.groupby(\"District\")\n",
        "dataframe_parquet_time_group_by = time.time() - start_time\n",
        "\n",
        "print(\"Group by time: \", str(dataframe_parquet_time_group_by))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMKsMEltwfj-"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTVP5ISSwfj-",
        "outputId": "f367d345-a0d1-420f-8634-2300e294a9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count time:  0.06302261352539062\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "counted_df = grouped_df.count()\n",
        "\n",
        "dataframe_parquet_count = time.time() - start_time\n",
        "print(\"Count time: \", str(dataframe_parquet_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6a1wtUwfj_"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0tn6j5twfj_",
        "outputId": "46c4d412-6592-4f19-a9c4-3d326f28fb9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sort time:  0.04057002067565918\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "sorted_df = counted_df.orderBy(\"count\", ascending=False)\n",
        "dataframe_parquet_time_sort = time.time() - start_time\n",
        "print(\"Sort time: \", str(dataframe_parquet_time_sort))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWYjLEOZy4pJ"
      },
      "source": [
        "###  2. PySpark RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "UjIvL6u_y4pJ"
      },
      "outputs": [],
      "source": [
        "#Install dependencies\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "hXbterA-y4pK"
      },
      "outputs": [],
      "source": [
        "# Crear SparkSession\n",
        "spark_session = SparkSession.builder \\\n",
        "    .appName(\"AddNumbers\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Obtener SparkContext desde SparkSession\n",
        "spark_context = spark_session.sparkContext\n",
        "\n",
        "spark_context.setLogLevel(\"ERROR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igGGwz_vy4pK"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRF268J78ny"
      },
      "source": [
        "Spark Context can't read a parquet file. So we read it using spark session and we parse it to RDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rM3-5QGy4pK",
        "outputId": "f4ec645c-a641-42c3-a8d9-6168fea6ca07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading time:  0.17148876190185547\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "spark_df = spark_session.read.parquet(path_parquet_file)\n",
        "rdd = spark_df.rdd\n",
        "rdd_parquet_reading_time = time.time() - initial_time\n",
        "print(\"Reading time: \", str(rdd_parquet_reading_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvURJQWj8yVO"
      },
      "source": [
        "Each row of the rdd is a list with the info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kdiw409y4pL"
      },
      "source": [
        "Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysR4c_t0y4pL",
        "outputId": "96578f82-ce80-4f72-d17c-e0da858d6807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter time:  0.00099945068359375\n"
          ]
        }
      ],
      "source": [
        "initial_time = time.time()\n",
        "rdd_filtered = rdd.filter(lambda row: row[\"Arrest\"] == True)\n",
        "\n",
        "rdd_parquet_filter_time = time.time() - initial_time\n",
        "print(\"Filter time: \", str(rdd_parquet_filter_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6fGZOr-y4pM"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qArfYayWy4pM",
        "outputId": "57c93c95-9ec3-4cfc-a450-7b81d8de60e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Group by time: 0.0\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_mapped = rdd_filtered.map(lambda row: (row[\"District\"], 1))\n",
        "\n",
        "rdd_parquet_time_group_by = time.time() - start_time\n",
        "\n",
        "print(\"Group by time:\", str(rdd_parquet_time_group_by))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2W1m1Zyy4pM"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Z2s_sZy4pM",
        "outputId": "c9c06045-e235-4a95-ea6a-c28d3f028f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Count time:  0.03737497329711914\n"
          ]
        },
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 79.0 failed 1 times, most recent failure: Lost task 6.0 in stage 79.0 (TID 673) (host.docker.internal executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor183.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[106], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m rdd_parquet_count \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount time: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(rdd_parquet_count))\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrdd_counted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:2836\u001b[0m, in \u001b[0;36mRDD.take\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   2833\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2835\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[1;32m-> 2836\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2838\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m   2839\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\context.py:2319\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m   2317\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m   2318\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2319\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
            "File \u001b[1;32mC:\\spark-3.4.4-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[1;32mC:\\spark-3.4.4-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 79.0 failed 1 times, most recent failure: Lost task 6.0 in stage 79.0 (TID 673) (host.docker.internal executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\r\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\r\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor183.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_counted = rdd_mapped.reduceByKey(lambda a, b: a + b)\n",
        "rdd_parquet_count = time.time() - start_time\n",
        "print(\"Count time: \", str(rdd_parquet_count))\n",
        "print(rdd_counted.take(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZMjzW5fy4pN"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDsQ0CIwy4pN",
        "outputId": "ae8ca49c-7f81-450e-e958-e874c116ea70"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 77.0 failed 1 times, most recent failure: Lost task 4.0 in stage 77.0 (TID 663) (host.docker.internal executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1022)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1021)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:76)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[105], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m rdd_counted_no_null \u001b[38;5;241m=\u001b[39m rdd_counted\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m rdd_sorted \u001b[38;5;241m=\u001b[39m \u001b[43mrdd_counted_no_null\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m rdd_parquet_time_sort \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSort time: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(rdd_parquet_time_sort))\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:1558\u001b[0m, in \u001b[0;36mRDD.sortBy\u001b[1;34m(self, keyfunc, ascending, numPartitions)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msortBy\u001b[39m(\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1521\u001b[0m     keyfunc: Callable[[T], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1522\u001b[0m     ascending: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1523\u001b[0m     numPartitions: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1524\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;124;03m    Sorts this RDD by the given keyfunc\u001b[39;00m\n\u001b[0;32m   1527\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03m    [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1558\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeyBy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[type-var]\u001b[39;49;00m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msortByKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumPartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m   1561\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:1495\u001b[0m, in \u001b[0;36mRDD.sortByKey\u001b[1;34m(self, ascending, numPartitions, keyfunc)\u001b[0m\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapPartitions(sortPartition, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;66;03m# first compute the boundary of each part via sampling: we want to partition\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;66;03m# the key-space into bins such that the bins have roughly the same\u001b[39;00m\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;66;03m# number of (key, value) pairs falling into them\u001b[39;00m\n\u001b[1;32m-> 1495\u001b[0m rddSize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rddSize:\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# empty RDD\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:2297\u001b[0m, in \u001b[0;36mRDD.count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;124;03m    Return the number of elements in this RDD.\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2295\u001b[0m \u001b[38;5;124;03m    3\u001b[39;00m\n\u001b[0;32m   2296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:2272\u001b[0m, in \u001b[0;36mRDD.sum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msum\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[NumberOrArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberOrArray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;124;03m    Add up the elements in this RDD.\u001b[39;00m\n\u001b[0;32m   2254\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;124;03m    6.0\u001b[39;00m\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   2273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\n\u001b[0;32m   2274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:2025\u001b[0m, in \u001b[0;36mRDD.fold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m   2020\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m acc\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;66;03m# collecting result of mapPartitions here ensures that the copy of\u001b[39;00m\n\u001b[0;32m   2023\u001b[0m \u001b[38;5;66;03m# zeroValue provided to each partition is unique from the one provided\u001b[39;00m\n\u001b[0;32m   2024\u001b[0m \u001b[38;5;66;03m# to the final reduce call\u001b[39;00m\n\u001b[1;32m-> 2025\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapPartitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(op, vals, zeroValue)\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\rdd.py:1814\u001b[0m, in \u001b[0;36mRDD.collect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext):\n\u001b[0;32m   1813\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1814\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectAndServe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
            "File \u001b[1;32mC:\\spark-3.4.4-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\cberd\\anaconda3\\envs\\spark342\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[1;32mC:\\spark-3.4.4-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 77.0 failed 1 times, most recent failure: Lost task 4.0 in stage 77.0 (TID 663) (host.docker.internal executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1022)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1021)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:193)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:76)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:578)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1589)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:192)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:166)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.api.python.PairwiseRDD.compute(PythonRDD.scala:128)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:367)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:331)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:694)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:738)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:690)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:655)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:631)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:588)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:546)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:179)\r\n\t... 20 more\r\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "rdd_counted_no_null = rdd_counted.filter(lambda x: x[1] is not None)\n",
        "rdd_sorted = rdd_counted_no_null.sortBy(lambda x: x[1], ascending=False)\n",
        "rdd_parquet_time_sort = time.time() - start_time\n",
        "print(\"Sort time: \", str(rdd_parquet_time_sort))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv4Jy4D3u3_y"
      },
      "source": [
        "### 3. Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMZ00XB_WV5Z"
      },
      "outputs": [],
      "source": [
        "# Lectura del archivo Parquet\n",
        "start_time = time.time()\n",
        "df = pd.read_parquet(\"data_parquet\", engine=\"pyarrow\")\n",
        "pdParquet_read_time = time.time() - start_time\n",
        "print(\"Tiempo de lectura (Pandas Parquet):\", pdParquet_read_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ss8oOWk_YPox",
        "outputId": "3502206e-1de4-455b-b971-b2d628790485"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'time' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3374ecfa357c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filtrado: seleccionar registros donde 'Arrest' es True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_filtrado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Arrest\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpdParquet_filter_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tiempo de filtrado (Pandas Parquet):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdParquet_filter_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ],
      "source": [
        "# Filtrado: seleccionar registros donde 'Arrest' es True\n",
        "start_time = time.time()\n",
        "df_filtrado = df[df[\"Arrest\"] == True]\n",
        "pdParquet_filter_time = time.time() - start_time\n",
        "print(\"Tiempo de filtrado (Pandas Parquet):\", pdParquet_filter_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3Xm2URSYR7n"
      },
      "outputs": [],
      "source": [
        "# Agrupación: agrupar por 'District' y contar registros en cada grupo\n",
        "start_time = time.time()\n",
        "# Aquí se realiza la agrupación y se crea una nueva columna 'count'\n",
        "df_agrupado = df_filtrado.groupby(\"District\").size().reset_index(name=\"count\")\n",
        "pdParquet_group_time = time.time() - start_time\n",
        "print(\"Tiempo de agrupación (Pandas Parquet):\", pdParquet_group_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvjsda1rYVAZ"
      },
      "outputs": [],
      "source": [
        "# Conteo: también se puede medir el tiempo de obtener el conteo de cada grupo\n",
        "start_time = time.time()\n",
        "df_count = df_filtrado.groupby(\"District\")[\"Arrest\"].count()\n",
        "pdParquet_count_time = time.time() - start_time\n",
        "print(\"Tiempo de conteo (Pandas Parquet):\", pdParquet_count_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX3tA44tYXeq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ordenamiento: ordenar los grupos por la columna 'count' de forma descendente\n",
        "start_time = time.time()\n",
        "df_sorted = df_agrupado.sort_values(by=\"count\", ascending=False)\n",
        "pdParquet_sort_time = time.time() - start_time\n",
        "print(\"Tiempo de ordenamiento (Pandas Parquet):\", pdParquet_sort_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9NGm64ru8ig"
      },
      "source": [
        "### 4. Polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIysjDRFGL3o"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeVV-2H-GfW-"
      },
      "source": [
        "Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohtVrqDeGiFD"
      },
      "outputs": [],
      "source": [
        "start_computing_time = time.time()\n",
        "df=pl.read_parquet(path_parquet_file)\n",
        "pl_parquet_reading_time= time.time()-start_computing_time\n",
        "print(\"Reading time: \",pl_parquet_reading_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0TpTWmG17s"
      },
      "source": [
        "Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIsJ2W8ZGnjg"
      },
      "outputs": [],
      "source": [
        "start_computing_time = time.time()\n",
        "filter_df= df.filter(pl.col(\"Arrest\") == True)\n",
        "pl_parquet_filter_time= time.time()-start_computing_time\n",
        "print(\"Filter time: \",pl_parquet_filter_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y45ugUjgG4u7"
      },
      "source": [
        "Group by"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFekY27mGqrZ"
      },
      "outputs": [],
      "source": [
        "start_computing_time = time.time()\n",
        "grouped_df=filter_df.group_by(\"District\")\n",
        "pl_parquet_group_time= time.time()-start_computing_time\n",
        "print(\"Group by time: \",pl_parquet_group_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SycqxIMsdONZ"
      },
      "source": [
        "Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXJj1UoVdNWX"
      },
      "outputs": [],
      "source": [
        "start_computing_time = time.time()\n",
        "count_df=grouped_df.agg(pl.len().alias(\"count\"))\n",
        "pl_parquet_count_time= time.time()-start_computing_time\n",
        "print(\"Group by time: \",pl_parquet_count_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgo9yKoNG_ii"
      },
      "source": [
        "Sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0KIJeD8GtEu"
      },
      "outputs": [],
      "source": [
        "start_computing_time = time.time()\n",
        "sort_df = count_df.sort(\"count\", descending=True)\n",
        "pl_parquet_sort_time= time.time()-start_computing_time\n",
        "print(\"Sort by time: \",pl_parquet_sort_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HojcrZC1HA-e"
      },
      "source": [
        "Total Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtgNjnl7GvrB"
      },
      "outputs": [],
      "source": [
        "pl_total_time=pl_parquet_reading_time+pl_parquet_filter_time+pl_parquet_group_time+pl_parquet_sort_time+pl_parquet_count_time\n",
        "print(\"Total time: \",pl_total_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2Il-ZT_vFtg"
      },
      "source": [
        "## Time Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rV-RgdrBLfN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24QlEecvBV7p"
      },
      "source": [
        "Stacked bar visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm8fbgzIHmJP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "colors = [\"red\", \"steelblue\", \"green\", \"purple\", \"orange\", \"brown\", \"magenta\", \"cyan\"]\n",
        "\n",
        "data = {\n",
        "    \"Method\": [\n",
        "        \"RDD Parquet\",\n",
        "        \"RDD CSV\",\n",
        "        \"SparkDF CSV\",\n",
        "        \"Spark DF Parquet\",\n",
        "        \"Polars CSV\",\n",
        "        \"Polars Parquet\",\n",
        "        \"Pandas CSV\",\n",
        "        \"Pandas Parquet\"\n",
        "    ],\n",
        "    \"Reading\": [\n",
        "        rdd_parquet_reading_time,\n",
        "        rdd_reading_time,\n",
        "        dataframe_reading_time,\n",
        "        dataframe_parquet_reading_time,\n",
        "        pl_reading_time,\n",
        "        pl_parquet_reading_time,\n",
        "        pd_read_time,\n",
        "        pdParquet_read_time\n",
        "    ],\n",
        "    \"Filtering\": [\n",
        "        rdd_parquet_filter_time,\n",
        "        rdd_filter_time,\n",
        "        dataframe_filter_time,\n",
        "        dataframe_parquet_filter_time,\n",
        "        pl_filter_time,\n",
        "        pl_parquet_filter_time,\n",
        "        pd_filter_time,\n",
        "        pdParquet_filter_time\n",
        "    ],\n",
        "    \"Grouping\": [\n",
        "        rdd_parquet_time_group_by,\n",
        "        rdd_time_group_by,\n",
        "        dataframe_time_group_by,\n",
        "        dataframe_parquet_time_group_by,\n",
        "        pl_group_time,\n",
        "        pl_parquet_group_time,\n",
        "        pd_group_time,\n",
        "        pdParquet_group_time\n",
        "    ],\n",
        "    \"Counting\": [\n",
        "        rdd_parquet_count,\n",
        "        rdd_count_time,\n",
        "        dataframe_count_time,\n",
        "        dataframe_parquet_count,\n",
        "        pl_count_time,\n",
        "        pl_parquet_count_time,\n",
        "        pd_count_time,\n",
        "        pdParquet_count_time\n",
        "    ],\n",
        "    \"Sorting\": [\n",
        "        rdd_parquet_time_sort,\n",
        "        rdd_time_sort,\n",
        "        dataframe_time_sort,\n",
        "        dataframe_parquet_time_sort,\n",
        "        pl_sort_time,\n",
        "        pl_parquet_sort_time,\n",
        "        pd_sort_time,\n",
        "        pdParquet_sort_time\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convertir el diccionario a un DataFrame de Pandas\n",
        "df_tiempos = pd.DataFrame(data)\n",
        "\n",
        "# Vector de ceros para, por ejemplo, usarse en gráficos apilados\n",
        "bottom = np.zeros(len(df_tiempos[\"Method\"]))\n",
        "\n",
        "print(df_tiempos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY2ILZbY_6T-"
      },
      "outputs": [],
      "source": [
        "#Mostrar datos\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0bzFq_yBU1N"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Crear gráfico de barras apiladas\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "# Graficar cada operación como una capa apilada\n",
        "for i, operation in enumerate([\"Reading\", \"Filtering\", \"Grouping\", \"Counting\", \"Sorting\"]):\n",
        "    ax.bar(df[\"Method\"], df[operation], bottom=bottom, label=operation, color=colors[i])\n",
        "    bottom += df[operation]\n",
        "\n",
        "# Agregar etiquetas\n",
        "ax.set_title(\"Performance Comparison \")\n",
        "ax.set_ylabel(\"Total Time (s)\")\n",
        "ax.legend(title=\"Operations\", loc=\"upper right\")\n",
        "\n",
        "# Rotar etiquetas en el eje X para mejor visualización\n",
        "plt.xticks(rotation=15)\n",
        "\n",
        "# Mostrar gráfico\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spark342",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
